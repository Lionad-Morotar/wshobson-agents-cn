---
name: data-quality-frameworks
description: ä½¿ç”¨ Great Expectationsã€dbt æµ‹è¯•ã€data contracts å’Œè‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥å®æ–½æ•°æ®è´¨é‡çš„æ¡†æ¶å’Œæ¨¡å¼ã€‚æ¶µç›– expectation suitesã€checkpointsã€è‡ªå®šä¹‰æµ‹è¯•å’Œè´¨é‡æŒ‡æ ‡ã€‚
---

# æ•°æ®è´¨é‡æ¡†æ¶

ä½¿ç”¨ Great Expectationsã€dbt æµ‹è¯•ã€data contracts å’Œè‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥å®æ–½å¯é æ•°æ®è´¨é‡æ¡†æ¶çš„ç»¼åˆæ¨¡å¼ã€‚è¿™äº›æ¨¡å¼ç¡®ä¿æ•°æ®å¯é æ€§ã€åŠæ—©å‘ç°é—®é¢˜ï¼Œå¹¶åœ¨æ•´ä¸ªæ•°æ®ç®¡é“ä¸­ç»´æŠ¤æ•°æ®æ ‡å‡†ã€‚

## ç®€ä»‹

æ•°æ®è´¨é‡æ¡†æ¶æä¾›ç»“æ„åŒ–çš„æ–¹æ³•æ¥éªŒè¯ã€ç›‘æ§å’Œç»´æŠ¤æ•´ä¸ªæ•°æ®ç®¡é“ä¸­çš„æ•°æ®è´¨é‡ã€‚è¿™åŒ…æ‹¬ï¼š

- **Great Expectations**ï¼šåŸºäº Python çš„æ•°æ®æ–‡æ¡£ã€è´¨é‡æœŸæœ›å’ŒéªŒè¯æ¡†æ¶
- **dbt Tests**ï¼šdbt æ¨¡å‹ä¸­åŸºäº SQL çš„æµ‹è¯•ï¼Œç”¨äºç¡®ä¿æ•°æ®å®Œæ•´æ€§å’Œä¸šåŠ¡é€»è¾‘
- **Data Contracts**ï¼šå®šä¹‰æœåŠ¡ä¹‹é—´æ•°æ®æ¨¡å¼ã€ç±»å‹å’Œè´¨é‡æ ‡å‡†çš„å½¢å¼åŒ–åè®®
- **Automated Quality Checks**ï¼šå¯¹æ•°æ®è´¨é‡æŒ‡æ ‡çš„æŒç»­ç›‘æ§å’Œå‘Šè­¦

è¿™äº›æ¡†æ¶å…±åŒå·¥ä½œï¼Œåˆ›å»ºå…¨é¢çš„æ•°æ®è´¨é‡ä¿è¯ï¼Œåœ¨é—®é¢˜å½±å“ä¸‹æ¸¸ç³»ç»Ÿä¹‹å‰æ•è·å®ƒä»¬ã€‚

## æ¨¡å¼

### 1. Expectation Suites

**ç›®æ ‡**ï¼šä½¿ç”¨ Great Expectations suites å®šä¹‰å…¨é¢çš„æ•°æ®è´¨é‡æœŸæœ›ã€‚

**æè¿°**ï¼šåˆ›å»ºå¯é‡ç”¨çš„ expectation suitesï¼Œæ ¹æ®å®šä¹‰çš„è´¨é‡è§„åˆ™éªŒè¯æ•°æ®ï¼ŒåŒ…æ‹¬ç±»å‹æ£€æŸ¥ã€å€¼èŒƒå›´å’Œè‡ªå®šä¹‰ä¸šåŠ¡é€»è¾‘ã€‚

**Implementation**:

```python
import great_expectations as ge
from great_expectations.core.batch import RuntimeBatchRequest

# åˆ›å»ºæ•°æ®ä¸Šä¸‹æ–‡
context = ge.get_context()

# å®šä¹‰ expectation suite
suite = context.add_or_update_expectation_suite("user_data_suite")

# æ·»åŠ æœŸæœ›
expectations = [
    # åˆ—å­˜åœ¨æ€§å’Œç±»å‹
    {
        "expectation_type": "expect_table_columns_to_match_ordered_list",
        "kwargs": {"column_list": ["user_id", "email", "created_at"]}
    },
    {
        "expectation_type": "expect_column_values_to_be_of_type",
        "kwargs": {"column": "user_id", "type_": "integer"}
    },
    
    # å€¼çº¦æŸ
    {
        "expectation_type": "expect_column_values_to_be_between",
        "kwargs": {"column": "age", "min_value": 18, "max_value": 120}
    },
    {
        "expectation_type": "expect_column_values_to_be_in_set",
        "kwargs": {"column": "status", "value_set": ["active", "inactive", "pending"]}
    },
    
    # å”¯ä¸€æ€§å’Œå®Œæ•´æ€§
    {
        "expectation_type": "expect_column_values_to_be_unique",
        "kwargs": {"column": "user_id"}
    },
    {
        "expectation_type": "expect_column_values_to_not_be_null",
        "kwargs": {"column": "email"}
    },
    
    # å­—ç¬¦ä¸²æ¨¡å¼
    {
        "expectation_type": "expect_column_values_to_match_regex",
        "kwargs": {"column": "email", "regex": r"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$"}
    },
    
    # è‡ªå®šä¹‰ä¸šåŠ¡é€»è¾‘
    {
        "expectation_type": "expect_column_values_to_be_increasing",
        "kwargs": {"column": "created_at"}
    }
]

for exp in expectations:
    suite.add_expectation(**exp)

# ä¿å­˜ suite
context.save_expectation_suite(suite)
```

**å…³é”®ç‰¹æ€§**ï¼š
- **åˆ—éªŒè¯**ï¼šæ£€æŸ¥åˆ—å­˜åœ¨æ€§ã€ç±»å‹å’Œé¡ºåº
- **å€¼çº¦æŸ**ï¼šéªŒè¯èŒƒå›´ã€é›†åˆå’Œæ¨¡å¼
- **ä¸šåŠ¡é€»è¾‘**ï¼šå®ç°è‡ªå®šä¹‰éªŒè¯è§„åˆ™
- **å¯é‡ç”¨æ€§**ï¼šè·¨ç¯å¢ƒå…±äº« expectation suites

### 2. Checkpoints å’ŒéªŒè¯

**ç›®æ ‡**ï¼šä½¿ç”¨ Great Expectations checkpoints è‡ªåŠ¨åŒ–æ•°æ®éªŒè¯ã€‚

**æè¿°**ï¼šåˆ›å»º checkpointsï¼Œå¯¹æ•°æ®æ‰¹æ¬¡è¿è¡Œ expectation suitesï¼Œç”ŸæˆéªŒè¯æŠ¥å‘Šï¼Œå¹¶åœ¨å¤±è´¥æ—¶è§¦å‘å‘Šè­¦ã€‚

**Implementation**:

```yaml
# great_expectations.yml
config_variables_file_name: config_variables.yml

stores:
  expectations_store:
    class_name: ExpectationsStore
    store_backend:
      class_name: TupleFilesystemStoreBackend
      base_directory: expectations/
  
  validations_store:
    class_name: ValidationsStore
    store_backend:
      class_name: TupleFilesystemStoreBackend
      base_directory: uncommitted/validations/
  
  evaluation_parameter_store:
    class_name: EvaluationParameterStore

expectations_store_name: expectations_store
validations_store_name: validations_store
evaluation_parameter_store_name: evaluation_parameter_store

data_docs_sites:
  local_site:
    class_name: SiteBuilder
    show_how_to_buttons: true
    store_backend:
      class_name: TupleFilesystemStoreBackend
      base_directory: uncommitted/data_docs/local_site
    site_index_builder:
      class_name: DefaultSiteIndexBuilder

checkpoint_config:
  class_name: SimpleCheckpoint
```

```python
# åˆ›å»º checkpoint
checkpoint_config = {
    "name": "user_data_checkpoint",
    "config_version": 1.0,
    "class_name": "SimpleCheckpoint",
    "run_name_template": "%Y%m%d-%H%M%S-user-data-validation",
    "expectation_suite_name": "user_data_suite",
    "action_list": [
        {
            "name": "store_validation_result",
            "action": {
                "class_name": "StoreValidationResultAction"
            }
        },
        {
            "name": "store_evaluation_params",
            "action": {
                "class_name": "StoreEvaluationParametersAction"
            }
        },
        {
            "name": "update_data_docs",
            "action": {
                "class_name": "UpdateDataDocsAction",
                "site_name": "local_site"
            }
        }
    ]
}

checkpoint = context.add_or_update_checkpoint(**checkpoint_config)

# è¿è¡Œ checkpoint
batch_request = RuntimeBatchRequest(
    datasource_name="my_datasource",
    data_connector_name="runtime_data_connector",
    data_asset_name="user_data",
    batch_identifiers={"batch_id": "latest"},
    runtime_parameters={"batch_data": user_data_df}
)

validation_result = checkpoint.run(batch_request=batch_request)

# æ£€æŸ¥ç»“æœ
if validation_result["success"]:
    print("âœ“ All expectations passed")
else:
    print("âœ— Validation failed")
    for result in validation_result["results"]:
        if not result["success"]:
            print(f"  - {result['expectation_config']['expectation_type']}: {result['expectation_config']['kwargs']}")
```

**å…³é”®ç‰¹æ€§**ï¼š
- **è‡ªåŠ¨åŒ–éªŒè¯**ï¼šæŒ‰è®¡åˆ’æˆ–äº‹ä»¶è§¦å‘è¿è¡Œæ£€æŸ¥
- **ä¸°å¯Œçš„æŠ¥å‘Š**ï¼šç”Ÿæˆè¯¦ç»†çš„éªŒè¯æŠ¥å‘Šå’Œæ•°æ®æ–‡æ¡£
- **å‘Šè­¦**ï¼šåœ¨éªŒè¯å¤±è´¥æ—¶è§¦å‘é€šçŸ¥
- **é›†æˆ**ï¼šä¸ Airflow ç­‰ç¼–æ’å·¥å…·é›†æˆ

### 3. dbt æµ‹è¯•

**ç›®æ ‡**ï¼šåœ¨ dbt æ¨¡å‹ä¸­å®ç°åŸºäº SQL çš„æµ‹è¯•ä»¥ç¡®ä¿æ•°æ®å®Œæ•´æ€§ã€‚

**æè¿°**ï¼šåˆ›å»º dbt æµ‹è¯•ï¼Œç›´æ¥åœ¨è½¬æ¢å±‚éªŒè¯æ•°æ®è´¨é‡ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§å’Œä¸šåŠ¡é€»è¾‘åˆè§„æ€§ã€‚

**Implementation**:

```sql
-- models/schema.yml

version: 2

models:
  - name: users
    description: "åŒ…å«å…¨é¢å±æ€§çš„ç”¨æˆ·ç»´åº¦è¡¨"
    columns:
      - name: user_id
        description: "æ¯ä¸ªç”¨æˆ·çš„å”¯ä¸€æ ‡è¯†ç¬¦"
        tests:
          - unique
          - not_null
      
      - name: email
        description: "ç”¨æˆ·ç”µå­é‚®ä»¶åœ°å€"
        tests:
          - unique
          - not_null
      
      - name: age
        description: "ç”¨æˆ·å¹´é¾„"
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "age >= 18"
      
      - name: status
        description: "ç”¨æˆ·è´¦æˆ·çŠ¶æ€"
        tests:
          - not_null
          - dbt_utils.relationships_where:
              to: ref('status_lookup')
              field: status_code
              from_condition: status IS NOT NULL
      
      - name: country
        description: "ç”¨æˆ·æ‰€åœ¨å›½å®¶"
        tests:
          - dbt_utils.is_in_reasonable_unit:
              reason: "ISO 3166-1 alpha-2 å›½å®¶ä»£ç "
              values: ['US', 'CA', 'GB', 'FR', 'DE', 'JP', 'AU']
```

```sql
-- tests/generic/user_email_format.sql

{% test user_email_format(model) %}

SELECT *
FROM {{ model }}
WHERE email NOT REGEXP '^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$'

{% endtest %}
```

```sql
-- tests/generic/user_has_recent_activity.sql

{% test user_has_recent_activity(model, date_column, days) %}

WITH latest_activity AS (
    SELECT MAX({{ date_column }}) as last_activity
    FROM {{ model }}
)

SELECT 1
FROM {{ model }}, latest_activity
WHERE {{ date_column }} < DATEADD(day, -{{ days }}, CURRENT_DATE)
HAVING COUNT(*) > 0

{% endtest %}
```

```sql
-- models/users.yml (ç»­)

models:
  - name: users
    columns:
      - name: email
        tests:
          - user_email_format
      
      - name: last_activity_date
        tests:
          - user_has_recent_activity:
              date_column: last_activity_date
              days: 30
```

**å…³é”®ç‰¹æ€§**ï¼š
- **å†…ç½®æµ‹è¯•**ï¼šä½¿ç”¨æ ‡å‡†æµ‹è¯•å¦‚ uniqueã€not_nullã€relationships
- **è‡ªå®šä¹‰æµ‹è¯•**ï¼šåˆ›å»ºç‰¹å®šé¢†åŸŸçš„æµ‹è¯•é€»è¾‘
- **é›†æˆ**ï¼šæµ‹è¯•éš dbt run è‡ªåŠ¨è¿è¡Œ
- **æ–‡æ¡£**ï¼šæµ‹è¯•ä½œä¸ºæ´»æ–‡æ¡£

### 4. è‡ªå®šä¹‰ dbt æµ‹è¯•

**ç›®æ ‡**ï¼šåˆ›å»ºé«˜çº§çš„ã€ç‰¹å®šé¢†åŸŸçš„ dbt æµ‹è¯•ä»¥è¿›è¡Œå¤æ‚éªŒè¯ã€‚

**æè¿°**ï¼šå®ç°è‡ªå®šä¹‰ dbt æµ‹è¯•ï¼Œç”¨äºå¤æ‚ä¸šåŠ¡é€»è¾‘ã€å¤šè¡¨éªŒè¯å’Œé«˜çº§æ•°æ®è´¨é‡æ£€æŸ¥ã€‚

**Implementation**:

```sql
-- tests/generic/range_check.sql

{% test range_check(model, column, min_value, max_value) %}

SELECT *
FROM {{ model }}
WHERE {{ column }} < {{ min_value }} OR {{ column }} > {{ max_value }}

{% endtest %}
```

```sql
-- tests/generic/multi_column_reference.sql

{% test multi_column_reference(model, column_list, reference_model, reference_column_list) %}

WITH model_values AS (
    SELECT {{ column_list|join(', ') }}
    FROM {{ model }}
    GROUP BY {{ column_list|join(', ') }}
),

reference_values AS (
    SELECT {{ reference_column_list|join(', ') }}
    FROM {{ reference_model }}
    GROUP BY {{ reference_column_list|join(', ') }}
)

SELECT mv.*
FROM model_values mv
LEFT JOIN reference_values rv
  ON mv.{{ column_list[0] }} = rv.{{ reference_column_list[0] }}
WHERE rv.{{ reference_column_list[0] }} IS NULL

{% endtest %}
```

```sql
-- tests/generic/business_rule.sql

{% test business_rule(model, rule_description, rule_sql) %}

{{ rule_description }}:
æ­¤æµ‹è¯•éªŒè¯è‡ªå®šä¹‰ä¸šåŠ¡è§„åˆ™ã€‚

è§„åˆ™ SQL: {{ rule_sql }}

SELECT *
FROM {{ model }}
WHERE NOT ({{ rule_sql }})

{% endtest %}
```

```sql
-- models/schema.yml (ä½¿ç”¨æ–¹æ³•)

models:
  - name: orders
    columns:
      - name: order_amount
        tests:
          - range_check:
              min_value: 0
              max_value: 1000000
      
      - name: user_id
        tests:
          - multi_column_reference:
              column_list: ['user_id', 'region']
              reference_model: ref('users')
              reference_column_list: ['user_id', 'region']
      
      - name: discount_percentage
        tests:
          - business_rule:
              rule_description: "æ™®é€šå®¢æˆ·çš„æŠ˜æ‰£ä¸åº”è¶…è¿‡ 50%"
              rule_sql: "customer_type = 'premium' OR discount_percentage <= 50"
```

**å…³é”®ç‰¹æ€§**ï¼š
- **å¯é‡ç”¨é€»è¾‘**ï¼šåˆ›å»ºå‚æ•°åŒ–çš„æµ‹è¯•å®
- **ä¸šåŠ¡è§„åˆ™**ï¼šå°†å¤æ‚ä¸šåŠ¡é€»è¾‘ç¼–ç ä¸ºæµ‹è¯•
- **è·¨è¡¨éªŒè¯**ï¼šéªŒè¯è¡¨ä¹‹é—´çš„å…³ç³»
- **å¯ç»´æŠ¤æ€§**ï¼šåœ¨å®ä¸­é›†ä¸­æµ‹è¯•é€»è¾‘

### 5. Data Contracts

**ç›®æ ‡**ï¼šå®šä¹‰å’Œå¼ºåˆ¶æ‰§è¡ŒæœåŠ¡ä¹‹é—´çš„ data contractsã€‚

**æè¿°**ï¼šåˆ›å»ºå½¢å¼åŒ–çš„ data contractsï¼ŒæŒ‡å®šæœåŠ¡ä¹‹é—´æ•°æ®äº¤æ¢çš„æ¨¡å¼ã€æ•°æ®ç±»å‹ã€çº¦æŸå’Œè´¨é‡æ ‡å‡†ã€‚

**Implementation**:

```python
# data_contract.py
from dataclasses import dataclass
from typing import List, Optional
from datetime import datetime

@dataclass
class FieldDefinition:
    name: str
    type: str
    nullable: bool = False
    unique: bool = False
    min_value: Optional[float] = None
    max_value: Optional[float] = None
    allowed_values: Optional[List[str]] = None
    pattern: Optional[str] = None

@dataclass
class DataContract:
    name: str
    version: str
    description: str
    fields: List[FieldDefinition]
    owner: str
    created_at: datetime
    updated_at: datetime
    sla: Optional[dict] = None

# å®šä¹‰ contract
user_contract = DataContract(
    name="user_data_contract",
    version="1.0.0",
    description="æœåŠ¡ä¹‹é—´äº¤æ¢çš„ç”¨æˆ·æ•°æ® contract",
    owner="data-team@company.com",
    created_at=datetime.now(),
    updated_at=datetime.now(),
    sla={
        "freshness": "1 hour",
        "completeness": "99.9%",
        "accuracy": "99.5%"
    },
    fields=[
        FieldDefinition(
            name="user_id",
            type="integer",
            nullable=False,
            unique=True
        ),
        FieldDefinition(
            name="email",
            type="string",
            nullable=False,
            unique=True,
            pattern=r"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$"
        ),
        FieldDefinition(
            name="age",
            type="integer",
            nullable=False,
            min_value=18,
            max_value=120
        ),
        FieldDefinition(
            name="status",
            type="string",
            nullable=False,
            allowed_values=["active", "inactive", "pending"]
        ),
        FieldDefinition(
            name="created_at",
            type="timestamp",
            nullable=False
        )
    ]
)

# æ ¹æ® contract éªŒè¯æ•°æ®
def validate_contract(data: pd.DataFrame, contract: DataContract) -> dict:
    results = {
        "valid": True,
        "errors": []
    }
    
    for field in contract.fields:
        # æ£€æŸ¥ç©ºå€¼
        if not field.nullable and data[field.name].isnull().any():
            results["valid"] = False
            results["errors"].append(f"å­—æ®µ '{field.name}' åŒ…å«ç©ºå€¼")
        
        # æ£€æŸ¥å”¯ä¸€æ€§
        if field.unique and data[field.name].duplicated().any():
            results["valid"] = False
            results["errors"].append(f"å­—æ®µ '{field.name}' åŒ…å«é‡å¤å€¼")
        
        # æ£€æŸ¥å€¼èŒƒå›´
        if field.min_value is not None and (data[field.name] < field.min_value).any():
            results["valid"] = False
            results["errors"].append(f"å­—æ®µ '{field.name}' åŒ…å«ä½äºæœ€å°å€¼çš„å€¼")
        
        if field.max_value is not None and (data[field.name] > field.max_value).any():
            results["valid"] = False
            results["errors"].append(f"å­—æ®µ '{field.name}' åŒ…å«é«˜äºæœ€å¤§å€¼çš„å€¼")
        
        # æ£€æŸ¥å…è®¸çš„å€¼
        if field.allowed_values:
            invalid = ~data[field.name].isin(field.allowed_values)
            if invalid.any():
                results["valid"] = False
                results["errors"].append(f"å­—æ®µ '{field.name}' åŒ…å«æ— æ•ˆå€¼")
    
    return results

# ä½¿ç”¨æ–¹æ³•
validation_result = validate_contract(user_data_df, user_contract)
print(validation_result)
```

**å…³é”®ç‰¹æ€§**ï¼š
- **æ¨¡å¼å®šä¹‰**ï¼šå½¢å¼åŒ–çš„æ¨¡å¼è§„èŒƒ
- **ç±»å‹å®‰å…¨**ï¼šå¼ºåˆ¶æ‰§è¡Œæ•°æ®ç±»å‹å’Œçº¦æŸ
- **SLA å¼ºåˆ¶æ‰§è¡Œ**ï¼šå®šä¹‰å’Œç›‘æ§æœåŠ¡çº§åˆ«åè®®
- **ç‰ˆæœ¬æ§åˆ¶**ï¼šè·Ÿè¸ª contract éšæ—¶é—´çš„å˜åŒ–

### 6. è‡ªåŠ¨åŒ–è´¨é‡ç®¡é“

**ç›®æ ‡**ï¼šæ„å»ºè‡ªåŠ¨åŒ–ç®¡é“ä»¥æŒç»­ç›‘æ§æ•°æ®è´¨é‡ã€‚

**æè¿°**ï¼šåˆ›å»ºè‡ªåŠ¨åŒ–ç®¡é“ï¼Œè¿è¡Œè´¨é‡æ£€æŸ¥ã€ç”ŸæˆæŠ¥å‘Šã€è§¦å‘å‘Šè­¦ï¼Œå¹¶ç»´æŠ¤æ•°æ®è´¨é‡ä»ªè¡¨æ¿ã€‚

**Implementation**:

```python
# quality_pipeline.py
import airflow
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.slack.operators.slack import SlackAPIPostOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'data-quality',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'data_quality_pipeline',
    default_args=default_args,
    description='è‡ªåŠ¨åŒ–æ•°æ®è´¨é‡ç›‘æ§ç®¡é“',
    schedule_interval='0 */6 * * *',  # æ¯ 6 å°æ—¶
    catchup=False,
    tags=['data-quality', 'monitoring']
)

def run_great_expectations_checkpoint():
    context = ge.get_context()
    checkpoint = context.get_checkpoint("user_data_checkpoint")
    result = checkpoint.run()
    
    if not result["success"]:
        raise Exception("Great Expectations éªŒè¯å¤±è´¥")
    
    return result

def run_dbt_tests():
    import subprocess
    result = subprocess.run(
        ['dbt', 'test', '--select', 'users'],
        capture_output=True,
        text=True
    )
    
    if result.returncode != 0:
        raise Exception(f"dbt æµ‹è¯•å¤±è´¥: {result.stderr}")
    
    return result.stdout

def check_data_freshness():
    query = """
        SELECT 
            MAX(created_at) as latest_record,
            TIMESTAMPDIFF(HOUR, MAX(created_at), NOW()) as hours_since_latest
        FROM users
    """
    
    df = pd.read_sql(query, engine)
    
    if df['hours_since_latest'].iloc[0] > 2:
        raise Exception(f"æ•°æ®æ–°é²œåº¦å‘Šè­¦: è·ç¦»æœ€æ–°è®°å½• {df['hours_since_latest'].iloc[0]} å°æ—¶")
    
    return df.to_dict()

def generate_quality_report():
    metrics = {
        "timestamp": datetime.now().isoformat(),
        "total_records": len(user_data_df),
        "null_counts": user_data_df.isnull().sum().to_dict(),
        "duplicate_count": user_data_df.duplicated().sum(),
        "data_freshness": check_data_freshness()
    }
    
    # ä¿å­˜æŠ¥å‘Š
    with open(f"reports/quality_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", 'w') as f:
        json.dump(metrics, f, indent=2)
    
    return metrics

def send_slack_alert(context):
    task_instance = context['task_instance']
    error_message = task_instance.xcom_pull(task_ids=context['task'].upstream_task_ids[-1])
    
    SlackAPIPostOperator(
        task_id='slack_alert',
        slack_conn_id='slack',
        channel='#data-quality',
        text=f"""
ğŸš¨ *æ•°æ®è´¨é‡å‘Šè­¦*

*ä»»åŠ¡*: {context['task'].task_id}
*DAG*: {context['dag'].dag_id}
*é”™è¯¯*: {str(error_message)}
*æ—¶é—´*: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """,
        username='Data Quality Bot'
    ).execute(context=context)

# å®šä¹‰ä»»åŠ¡
ge_task = PythonOperator(
    task_id='run_great_expectations',
    python_callable=run_great_expectations_checkpoint,
    dag=dag
)

dbt_task = PythonOperator(
    task_id='run_dbt_tests',
    python_callable=run_dbt_tests,
    dag=dag
)

freshness_task = PythonOperator(
    task_id='check_data_freshness',
    python_callable=check_data_freshness,
    dag=dag
)

report_task = PythonOperator(
    task_id='generate_quality_report',
    python_callable=generate_quality_report,
    dag=dag
)

alert_task = SlackAPIPostOperator(
    task_id='send_slack_alert',
    slack_conn_id='slack',
    channel='#data-quality',
    text="""
ğŸš¨ *æ•°æ®è´¨é‡å‘Šè­¦*

ä¸€ä¸ªæˆ–å¤šä¸ªè´¨é‡æ£€æŸ¥å¤±è´¥ã€‚è¯·è¿›è¡Œè°ƒæŸ¥ã€‚
    """,
    trigger_rule='one_failed',
    dag=dag
)

# è®¾ç½®ä»»åŠ¡ä¾èµ–
[ge_task, dbt_task, freshness_task] >> report_task >> alert_task
```

**å…³é”®ç‰¹æ€§**ï¼š
- **è‡ªåŠ¨åŒ–æ£€æŸ¥**ï¼šè‡ªåŠ¨è®¡åˆ’å¹¶è¿è¡Œè´¨é‡æ£€æŸ¥
- **å‘Šè­¦**ï¼šåœ¨è´¨é‡å¤±è´¥æ—¶è§¦å‘å‘Šè­¦
- **æŠ¥å‘Š**ï¼šç”Ÿæˆå…¨é¢çš„è´¨é‡æŠ¥å‘Š
- **é›†æˆ**ï¼šä¸ç¼–æ’å¹³å°é›†æˆ

## æœ€ä½³å®è·µ

1. **ä»ç®€å•å¼€å§‹**ï¼šä»åŸºæœ¬éªŒè¯å¼€å§‹ï¼Œé€æ­¥å¢åŠ å¤æ‚æ€§
2. **å…·ä½“æ˜ç¡®**ï¼šä¸ºå…³é”®æ•°æ®è´¨é‡è§„åˆ™åˆ›å»ºæœ‰é’ˆå¯¹æ€§çš„æµ‹è¯•
3. **è‡ªåŠ¨åŒ–**ï¼šè‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥ä»¥å°½æ—©å‘ç°é—®é¢˜
4. **ç›‘æ§**ï¼šæŒç»­ç›‘æ§è´¨é‡æŒ‡æ ‡å’Œè¶‹åŠ¿
5. **æ–‡æ¡£**ï¼šè®°å½•è´¨é‡è§„åˆ™åŠå…¶ä¸šåŠ¡ä¾æ®
6. **ç‰ˆæœ¬æ§åˆ¶**ï¼šå°†è´¨é‡å®šä¹‰å­˜å‚¨åœ¨ç‰ˆæœ¬æ§åˆ¶ä¸­
7. **å®šæœŸå®¡æŸ¥**ï¼šéšç€æ•°æ®éœ€æ±‚çš„å‘å±•å®¡æŸ¥å’Œæ›´æ–°æµ‹è¯•

## èµ„æº

- [Great Expectations æ–‡æ¡£](https://docs.greatexpectations.io/)
- [dbt æµ‹è¯•æŒ‡å—](https://docs.getdbt.com/docs/build/tests)
- [Data Contract è§„èŒƒ](https://www.datacontract.com/)
- [æ•°æ®è´¨é‡æœ€ä½³å®è·µ](https://www.datamesh-architecture.com/data-quality)
