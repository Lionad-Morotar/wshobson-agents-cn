# workflow-automate

ä½¿ç”¨å·¥ä½œæµè‡ªåŠ¨åŒ–å‘½ä»¤ç®€åŒ–å¼€å‘å·¥ä½œæµç¨‹ã€CI/CD æµæ°´çº¿å’ŒåŸºç¡€è®¾æ–½ç®¡ç†ã€‚

## åŠŸèƒ½æ¦‚è¿°

å·¥ä½œæµè‡ªåŠ¨åŒ–å‘½ä»¤æä¾›å…¨é¢çš„å·¥å…·é›†ç”¨äºï¼š
- GitHub Actions å·¥ä½œæµåˆ†æ
- CI/CD æµæ°´çº¿ç”Ÿæˆ
- å‘å¸ƒè‡ªåŠ¨åŒ–
- å¼€å‘å·¥ä½œæµè‡ªåŠ¨åŒ–
- åŸºç¡€è®¾æ–½è‡ªåŠ¨åŒ–
- ç›‘æ§å’Œå¯è§‚æµ‹æ€§
- å®‰å…¨æ‰«æé›†æˆ
- å·¥ä½œæµç¼–æ’

## å·¥ä½œæµåˆ†æ

åœ¨å®æ–½è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆä¹‹å‰ï¼Œåˆ†æå½“å‰çš„å·¥ä½œæµå’Œè¯†åˆ«æ”¹è¿›é¢†åŸŸã€‚

### workflow_analyzer.py

```python
#!/usr/bin/env python3
"""
å·¥ä½œæµåˆ†æå™¨ - åˆ†æ GitHub Actions å·¥ä½œæµå’Œè¯†åˆ«è‡ªåŠ¨åŒ–æœºä¼š

åˆ†æ GitHub Actions å·¥ä½œæµæ–‡ä»¶ã€è¯†åˆ«ç“¶é¢ˆã€ä¼˜åŒ–æœºä¼šå¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚
"""

import yaml
import json
from pathlib import Path
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime, timedelta


@dataclass
class WorkflowMetrics:
    """å·¥ä½œæµæŒ‡æ ‡"""
    name: str
    total_runs: int
    avg_duration: timedelta
    success_rate: float
    jobs_count: int
    critical_path: List[str]
    optimization_opportunities: List[str]


class WorkflowAnalyzer:
    """GitHub Actions å·¥ä½œæµåˆ†æå™¨"""
    
    def __init__(self, repo_path: str):
        self.repo_path = Path(repo_path)
        self.workflows_dir = self.repo_path / ".github" / "workflows"
        
    def analyze_workflows(self) -> Dict[str, WorkflowMetrics]:
        """åˆ†ææ‰€æœ‰å·¥ä½œæµå¹¶è®¡ç®—æŒ‡æ ‡"""
        metrics = {}
        
        for workflow_file in self.workflows_dir.glob("*.yml"):
            workflow = self._parse_workflow(workflow_file)
            if workflow:
                workflow_name = workflow.get("name", workflow_file.stem)
                metrics[workflow_name] = self._calculate_metrics(workflow)
                
        return metrics
    
    def _parse_workflow(self, workflow_file: Path) -> Dict[str, Any]:
        """è§£æå·¥ä½œæµ YAML æ–‡ä»¶"""
        try:
            with open(workflow_file, 'r') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"Error parsing {workflow_file}: {e}")
            return None
    
    def _calculate_metrics(self, workflow: Dict[str, Any]) -> WorkflowMetrics:
        """è®¡ç®—å·¥ä½œæµæŒ‡æ ‡"""
        jobs = workflow.get("jobs", {})
        jobs_count = len(jobs)
        
        return WorkflowMetrics(
            name=workflow.get("name", "Unknown"),
            total_runs=0,  # ä» GitHub API è·å–
            avg_duration=timedelta(minutes=5),
            success_rate=0.95,
            jobs_count=jobs_count,
            critical_path=self._identify_critical_path(jobs),
            optimization_opportunities=self._find_optimizations(jobs)
        )
    
    def _identify_critical_path(self, jobs: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«å…³é”®è·¯å¾„ä¸­çš„ä»»åŠ¡"""
        critical = []
        for job_name, job_config in jobs.items():
            needs = job_config.get("needs", [])
            if not needs:  # èµ·å§‹ä»»åŠ¡
                critical.append(job_name)
        return critical
    
    def _find_optimizations(self, jobs: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«ä¼˜åŒ–æœºä¼š"""
        optimizations = []
        
        for job_name, job_config in jobs.items():
            steps = job_config.get("steps", [])
            
            # æ£€æŸ¥ç¼“å­˜æœºä¼š
            if any("npm install" in str(step) for step in steps):
                optimizations.append(f"{job_name}: æ·»åŠ  npm ç¼“å­˜")
            
            # æ£€æŸ¥å¹¶è¡ŒåŒ–æœºä¼š
            if job_config.get("matrix"):
                optimizations.append(f"{job_name}: ä¼˜åŒ–çŸ©é˜µç­–ç•¥")
                
        return optimizations
    
    def generate_report(self, metrics: Dict[str, WorkflowMetrics]) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = ["# å·¥ä½œæµåˆ†ææŠ¥å‘Š", ""]
        
        for workflow_name, metric in metrics.items():
            report.append(f"## {workflow_name}")
            report.append(f"- ä»»åŠ¡æ•°: {metric.jobs_count}")
            report.append(f"- å¹³å‡æŒç»­æ—¶é—´: {metric.avg_duration}")
            report.append(f"- æˆåŠŸç‡: {metric.success_rate:.1%}")
            report.append(f"- ä¼˜åŒ–æœºä¼š: {len(metric.optimization_opportunities)}")
            report.append("")
            
        return "\n".join(report)


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: workflow_analyzer.py <repo_path>")
        sys.exit(1)
    
    analyzer = WorkflowAnalyzer(sys.argv[1])
    metrics = analyzer.analyze_workflows()
    report = analyzer.generate_report(metrics)
    print(report)


if __name__ == "__main__":
    main()
```

## CI/CD æµæ°´çº¿

åˆ›å»ºå¥å£®çš„ CI/CD æµæ°´çº¿ç”¨äºè‡ªåŠ¨åŒ–æµ‹è¯•ã€æ„å»ºå’Œéƒ¨ç½²ã€‚

### .github/workflows/ci-cd.yml

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

env:
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ä»£ç è´¨é‡æ£€æŸ¥
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: è®¾ç½® Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: å®‰è£…ä¾èµ–
        run: npm ci
      
      - name: è¿è¡Œ Lint
        run: npm run lint
      
      - name: è¿è¡Œç±»å‹æ£€æŸ¥
        run: npm run type-check
      
      - name: ä»£ç æ ¼å¼æ£€æŸ¥
        run: npm run format:check

  # å®‰å…¨æ‰«æ
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è¿è¡Œ Trivy æ¼æ´æ‰«æ
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: ä¸Šä¼  Trivy ç»“æœåˆ° GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # æµ‹è¯•
  test:
    name: Test
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [18, 20, 21]
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: å®‰è£…ä¾èµ–
        run: npm ci
      
      - name: è¿è¡Œå•å…ƒæµ‹è¯•
        run: npm run test:unit
      
      - name: è¿è¡Œé›†æˆæµ‹è¯•
        run: npm run test:integration
      
      - name: ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
        run: npm run test:coverage
      
      - name: ä¸Šä¼ è¦†ç›–ç‡åˆ° Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella

  # æ„å»º
  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [code-quality, security-scan, test]
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: å®‰è£…ä¾èµ–
        run: npm ci
      
      - name: æ„å»ºé¡¹ç›®
        run: npm run build
      
      - name: ä¸Šä¼ æ„å»ºäº§ç‰©
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: dist/
          retention-days: 7

  # Docker é•œåƒæ„å»ºå’Œæ¨é€
  docker-build:
    name: Docker Build & Push
    runs-on: ubuntu-latest
    needs: [build]
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: ç™»å½•åˆ° GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: æå– Docker å…ƒæ•°æ®
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-
      
      - name: æ„å»ºå¹¶æ¨é€ Docker é•œåƒ
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

  # éƒ¨ç½²åˆ°é¢„å‘å¸ƒç¯å¢ƒ
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [docker-build]
    if: github.ref == 'refs/heads/develop'
    environment:
      name: staging
      url: https://staging.example.com
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® kubectl
        uses: azure/setup-kubectl@v3
      
      - name: é…ç½® kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > $HOME/.kube/config
      
      - name: éƒ¨ç½²åˆ° Kubernetes
        run: |
          kubectl set image deployment/app \
            app=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }} \
            -n staging
          kubectl rollout status deployment/app -n staging

  # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [docker-build]
    if: github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://example.com
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® kubectl
        uses: azure/setup-kubectl@v3
      
      - name: é…ç½® kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > $HOME/.kube/config
      
      - name: éƒ¨ç½²åˆ° Kubernetes
        run: |
          kubectl set image deployment/app \
            app=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }} \
            -n production
          kubectl rollout status deployment/app -n production
      
      - name: éªŒè¯éƒ¨ç½²
        run: |
          kubectl get pods -n production
          kubectl get services -n production

  # æ€§èƒ½æµ‹è¯•
  performance-test:
    name: Performance Test
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.ref == 'refs/heads/develop'
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è¿è¡Œ Lighthouse CI
        uses: treosh/lighthouse-ci-action@v10
        with:
          urls: |
            https://staging.example.com
          uploadArtifacts: true
          temporaryPublicStorage: true

  # é€šçŸ¥
  notify:
    name: Notify
    runs-on: ubuntu-latest
    needs: [deploy-production, performance-test]
    if: always()
    steps:
      - name: å‘é€ Slack é€šçŸ¥
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'éƒ¨ç½²å®Œæˆ: ${{ github.ref }}'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

## å‘å¸ƒè‡ªåŠ¨åŒ–

è‡ªåŠ¨åŒ–è¯­ä¹‰åŒ–ç‰ˆæœ¬å’Œå‘å¸ƒç®¡ç†ã€‚

### .github/workflows/release.yml

```yaml
name: Release Automation

on:
  push:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: write

jobs:
  release:
    name: Semantic Release
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: false
      
      - name: è®¾ç½® Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      
      - name: å®‰è£…ä¾èµ–
        run: npm ci
      
      - name: è¿è¡Œæµ‹è¯•
        run: npm test
      
      - name: æ„å»ºé¡¹ç›®
        run: npm run build
      
      - name: åˆ›å»º Release
        id: release
        uses: semantic-release/semantic-release@v22
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NPM_TOKEN: ${{ secrets.NPM_TOKEN }}
        with:
          branches: ['main']
          plugins: |
            @semantic-release/commit-analyzer
            @semantic-release/release-notes-generator
            @semantic-release/github
            @semantic-release/npm
      
      - name: ä¸Šä¼  Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-artifacts
          path: |
            dist/
            package.json
            package-lock.json
          if-no-files-found: error
      
      - name: åˆ›å»º GitHub Release
        if: steps.release.outputs.new_release_published == 'true'
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ steps.release.outputs.git_tag }}
          release_name: Release ${{ steps.release.outputs.git_tag }}
          body: ${{ steps.release.outputs.notes }}
          draft: false
          prerelease: false
```

## å¼€å‘å·¥ä½œæµè‡ªåŠ¨åŒ–

è‡ªåŠ¨åŒ–å¸¸è§å¼€å‘ä»»åŠ¡å¹¶å¼ºåˆ¶æ‰§è¡Œæœ€ä½³å®è·µã€‚

### .github/workflows/pr-automation.yml

```yaml
name: PR Automation

on:
  pull_request:
    types: [opened, synchronize, reopened, edited]
  pull_request_review:
    types: [submitted, edited, dismissed]

jobs:
  # è‡ªåŠ¨æ ‡ç­¾
  auto-label:
    name: Auto Label
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è‡ªåŠ¨æ ‡ç­¾
        uses: actions/labeler@v5
        with:
          repo-token: ${{ secrets.GITHUB_TOKEN }}
          configuration-path: .github/labeler.yml
          sync-labels: true

  # PR éªŒè¯
  pr-validation:
    name: PR Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: æ£€æŸ¥ PR æè¿°
        uses: techsteplez/pr-description-checker@v2
        with:
          fail_on_error: true
          min_length: 20
      
      - name: æ£€æŸ¥é“¾æ¥ä»»åŠ¡
        uses: nearform/github-action-check-linked-issues@v1
        with:
          excludeFromBranch: main,develop
          customNotLinkedMessage: "è¯·å°†æ­¤ PR é“¾æ¥åˆ°ä¸€ä¸ª issue"
      
      - name: æ£€æŸ¥æäº¤ç­¾å
        uses: 1Francis1/commit-sign-check@v1
        with:
          allowed-actors: dependabot[bot], renovate[bot]

  # ä»£ç å®¡æŸ¥åˆ†é…
  assign-reviewers:
    name: Assign Reviewers
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: åˆ†é…ä»£ç å®¡æŸ¥è€…
        uses: kentaro-m/auto-assign-action@v2
        with:
          configuration-path: .github/auto_assign.yml
          repo-token: ${{ secrets.GITHUB_TOKEN }}

  # è‡ªåŠ¨åˆå¹¶ä¾èµ–æ›´æ–°
  auto-merge-dependencies:
    name: Auto Merge Dependencies
    runs-on: ubuntu-latest
    if: github.actor == 'dependabot[bot]' || github.actor == 'renovate[bot]'
    steps:
      - name: ç­‰å¾… CI æ£€æŸ¥é€šè¿‡
        uses: lewagon/wait-on-check-action@v1.3.1
        with:
          ref: ${{ github.event.pull_request.head.sha }}
          check-name: 'Code Quality'
          repo-token: ${{ secrets.GITHUB_TOKEN }}
          wait-interval: 10
      
      - name: è‡ªåŠ¨åˆå¹¶
        uses: ahmadnassri/action-dependabot-auto-merge@v2
        with:
          target: minor
          github-token: ${{ secrets.GITHUB_TOKEN }}

  # å¤§å‹ PR è­¦å‘Š
  large-pr-warning:
    name: Large PR Warning
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: æ£€æŸ¥ PR å¤§å°
        uses: action-reviews/large-pr-warning@v2
        with:
          files_limit: 500
          lines_limit: 2000
          comment_message: "è¿™ä¸ª PR éå¸¸å¤§ï¼Œè¯·è€ƒè™‘å°†å…¶æ‹†åˆ†ä¸ºæ›´å°çš„ PR ä»¥ä¾¿äºå®¡æŸ¥"
```

### pre-commit-config.yaml

```yaml
# Pre-commit é’©å­é…ç½®
# å®‰è£…: pip install pre-commit
# è¿è¡Œ: pre-commit install

default_language_version:
  python: python3.11
  node: "20"

repos:
  # é€šç”¨æ–‡ä»¶æ£€æŸ¥
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-json
      - id: check-toml
      - id: check-merge-conflict
      - id: detect-private-key
      - id: mixed-line-ending

  # Python ç‰¹å®šæ£€æŸ¥
  - repo: https://github.com/psf/black
    rev: 24.3.0
    hooks:
      - id: black
        language_version: python3.11

  - repo: https://github.com/pycqa/flake8
    rev: 7.0.0
    hooks:
      - id: flake8
        args: ['--max-line-length=100']

  - repo: https://github.com/pycqa/isort
    rev: 5.13.2
    hooks:
      - id: isort
        args: ['--profile', 'black']

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.8.0
    hooks:
      - id: mypy
        additional_dependencies:
          - types-requests
          - types-PyYAML

  # JavaScript/TypeScript æ£€æŸ¥
  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: v3.1.0
    hooks:
      - id: prettier
        types_or: [javascript, jsx, ts, tsx, css,scss, json, markdown]
        exclude: package-lock.json

  - repo: https://github.com/pre-commit/mirrors-eslint
    rev: v8.57.0
    hooks:
      - id: eslint
        types_or: [javascript, jsx, ts, tsx]
        args: ['--fix']

  # å®‰å…¨æ£€æŸ¥
  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.8
    hooks:
      - id: bandit
        args: ['-c', 'pyproject.toml']

  - repo: https://github.com/Yelp/detect-secrets
    rev: v1.4.0
    hooks:
      - id: detect-secrets
        args: ['--baseline', '.secrets.baseline']

  # Dockerfile æ£€æŸ¥
  - repo: https://github.com/hadolint/hadolint
    rev: v2.12.0
    hooks:
      - id: hadolint-docker
        args: ['--ignore', 'DL3008']

  # Markdown æ£€æŸ¥
  - repo: https://github.com/igorshubovych/markdownlint-cli
    rev: v0.39.0
    hooks:
      - id: markdownlint
        args: ['--fix']

  # Terraform æ£€æŸ¥
  - repo: https://github.com/antonbabenko/pre-commit-terraform
    rev: v1.83.2
    hooks:
      - id: terraform_fmt
      - id: terraform_validate
      - id: terraform_tflint
        args: ['--args=--module']
      - id: terraform_docs
        args: ['--args=--sort-by-required']
      - id: terraform_tfsec
        args: ['--args=--exclude-downloaded-modules']

  # Kubernetes æ¸…å•æ£€æŸ¥
  - repo: https://github.com/instrumenta/kubeval
    rev: v0.16.1
    hooks:
      - id: kubeval
        files: .*\.yaml$
```

### scripts/setup-dev.sh

```bash
#!/bin/bash
# å¼€å‘ç¯å¢ƒè‡ªåŠ¨åŒ–è®¾ç½®è„šæœ¬

set -e

echo "ğŸš€ å¼€å§‹è®¾ç½®å¼€å‘ç¯å¢ƒ..."

# æ£€æµ‹æ“ä½œç³»ç»Ÿ
OS="$(uname -s)"
echo "æ£€æµ‹åˆ°æ“ä½œç³»ç»Ÿ: $OS"

# å®‰è£… Homebrew (macOS)
if [[ "$OS" == "Darwin" ]]; then
    if ! command -v brew &> /dev/null; then
        echo "ğŸ“¦ å®‰è£… Homebrew..."
        /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
    else
        echo "âœ… Homebrew å·²å®‰è£…"
    fi
fi

# å®‰è£…ä¾èµ–å·¥å…·
echo "ğŸ”§ å®‰è£…å¼€å‘å·¥å…·..."

if [[ "$OS" == "Darwin" ]]; then
    brew install node@20 python@3.11 git kubectl helm terraform vault jq
elif [[ "$OS" == "Linux" ]]; then
    sudo apt-get update
    sudo apt-get install -y nodejs npm python3.11 python3-pip git kubectl helm terraform vault jq
fi

# å®‰è£… Node.js ä¾èµ–
if [ -f "package.json" ]; then
    echo "ğŸ“¦ å®‰è£… Node.js ä¾èµ–..."
    npm install
fi

# å®‰è£… Python ä¾èµ–
if [ -f "requirements.txt" ] || [ -f "pyproject.toml" ]; then
    echo "ğŸ“¦ å®‰è£… Python ä¾èµ–..."
    pip install -r requirements.txt || pip install .
fi

# å®‰è£… pre-commit é’©å­
if [ -f ".pre-commit-config.yaml" ]; then
    echo "ğŸª å®‰è£… pre-commit é’©å­..."
    pip install pre-commit
    pre-commit install
fi

# å®‰è£… Husky (Node.js é’©å­)
if [ -f "package.json" ]; then
    echo "ğŸª å®‰è£… Husky é’©å­..."
    npm install -g husky
    npx husky install
fi

# è®¾ç½® Docker
if ! command -v docker &> /dev/null; then
    echo "ğŸ³ Docker æœªå®‰è£…ã€‚è¯·ä» https://www.docker.com/products/docker-desktop ä¸‹è½½"
fi

# è®¾ç½® kubectl è‡ªåŠ¨å®Œæˆ
if command -v kubectl &> /dev/null; then
    echo "âš¡ è®¾ç½® kubectl è‡ªåŠ¨å®Œæˆ..."
    if [[ "$SHELL" == *"zsh"* ]]; then
        echo "source <(kubectl completion zsh)" >> ~/.zshrc
    elif [[ "$SHELL" == *"bash"* ]]; then
        echo "source <(kubectl completion bash)" >> ~/.bashrc
    fi
fi

# è®¾ç½® git è‡ªåŠ¨å®Œæˆ
if command -v git &> /dev/null; then
    echo "âš¡ è®¾ç½® git è‡ªåŠ¨å®Œæˆ..."
    if [[ "$SHELL" == *"zsh"* ]]; then
        echo "autoload -Uz compinit && compinit" >> ~/.zshrc
    elif [[ "$SHELL" == *"bash"* ]]; then
        curl https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash -o ~/.git-completion.bash
        echo "source ~/.git-completion.bash" >> ~/.bashrc
    fi
fi

# åˆ›å»º .env æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if [ ! -f ".env" ]; then
    echo "ğŸ“ åˆ›å»º .env æ–‡ä»¶..."
    cp .env.example .env 2>/dev/null || echo "# ç¯å¢ƒå˜é‡" > .env
fi

echo "âœ… å¼€å‘ç¯å¢ƒè®¾ç½®å®Œæˆï¼"
echo ""
echo "ä¸‹ä¸€æ­¥ï¼š"
echo "1. ç¼–è¾‘ .env æ–‡ä»¶å¹¶æ·»åŠ å¿…è¦çš„ API å¯†é’¥"
echo "2. è¿è¡Œ 'npm run dev' æˆ– 'python main.py' å¯åŠ¨å¼€å‘æœåŠ¡å™¨"
echo "3. è¿è¡Œ 'npm test' æˆ– 'pytest' è¿è¡Œæµ‹è¯•"
```

## åŸºç¡€è®¾æ–½è‡ªåŠ¨åŒ–

ä½¿ç”¨ Terraform å’Œå…¶ä»–å·¥å…·è‡ªåŠ¨åŒ–åŸºç¡€è®¾æ–½é…ç½®ã€‚

### .github/workflows/terraform.yml

```yaml
name: Infrastructure Automation

on:
  push:
    branches: [main]
    paths: ['terraform/**']
  pull_request:
    branches: [main]
    paths: ['terraform/**']
  workflow_dispatch:

jobs:
  # Terraform æ ¼å¼åŒ–å’ŒéªŒè¯
  terraform-format:
    name: Terraform Format
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - name: Terraform Format
        run: terraform fmt -check
        working-directory: terraform

  # Terraform å®‰å…¨æ‰«æ
  terraform-scan:
    name: Terraform Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è¿è¡Œ tfsec
        uses: aquasecurity/tfsec-sarif-action@v0.1.0
        with:
          sarif_file: tfsec-results.sarif
      
      - name: ä¸Šä¼  tfsec ç»“æœåˆ° GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: tfsec-results.sarif

  # Terraform è§„åˆ’
  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    env:
      TF_VAR_environment: staging
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - name: é…ç½® AWS å‡­è¯
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Terraform Init
        run: terraform init
        working-directory: terraform
      
      - name: Terraform Validate
        run: terraform validate
        working-directory: terraform
      
      - name: Terraform Plan
        id: plan
        run: terraform plan -no-color -out=tfplan
        working-directory: terraform
        continue-on-error: true
      
      - name: ä¿å­˜ Terraform è®¡åˆ’
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan
          path: terraform/tfplan
      
      - name: è¯„è®º PR
        uses: actions/github-script@v7
        if: github.event_name == 'pull_request'
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const output = `#### Terraform Format and Style ğŸ–Œï¸\`${{ steps.fmt.outcome }}\`
            #### Terraform Initialization âš™ï¸\`${{ steps.init.outcome }}\`
            #### Terraform Plan ğŸ“–\`${{ steps.plan.outcome }}\`
            #### Terraform Validation ğŸ¤–\`${{ steps.validate.outcome }}\`
            
            <details><summary>Show Plan</summary>
            
            \`\`\`\`
            ${{ steps.plan.outputs.stdout }}
            \`\`\`\`
            
            </details>
            
            *Pushed by: @${{ github.actor }}, Action: \`${{ github.event_name }}\`*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            })

  # Terraform åº”ç”¨
  terraform-apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    needs: [terraform-format, terraform-scan]
    env:
      TF_VAR_environment: production
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - name: é…ç½® AWS å‡­è¯
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Terraform Init
        run: terraform init
        working-directory: terraform
      
      - name: Terraform Apply
        run: terraform apply -auto-approve
        working-directory: terraform
      
      - name: è¾“å‡ºèµ„æºä¿¡æ¯
        id: output
        run: terraform output -json
        working-directory: terraform
```

### scripts/deploy-infrastructure.py

```python
#!/usr/bin/env python3
"""
åŸºç¡€è®¾æ–½éƒ¨ç½²è‡ªåŠ¨åŒ–è„šæœ¬

è‡ªåŠ¨åŒ– Terraform éƒ¨ç½²ã€éªŒè¯å’Œåéƒ¨ç½²é…ç½®ã€‚
"""

import subprocess
import json
import sys
import time
from pathlib import Path
from typing import Dict, List, Any
import argparse


class InfrastructureDeployer:
    """åŸºç¡€è®¾æ–½éƒ¨ç½²ç®¡ç†å™¨"""
    
    def __init__(self, environment: str, terraform_dir: str = "terraform"):
        self.environment = environment
        self.terraform_dir = Path(terraform_dir)
        self.state_file = self.terraform_dir / "terraform.tfstate"
        
    def run_terraform(self, command: List[str], capture_output: bool = True) -> subprocess.CompletedProcess:
        """è¿è¡Œ Terraform å‘½ä»¤"""
        cmd = ["terraform", *command]
        print(f"è¿è¡Œ: {' '.join(cmd)}")
        
        result = subprocess.run(
            cmd,
            cwd=self.terraform_dir,
            capture_output=capture_output,
            text=True
        )
        
        if result.returncode != 0:
            print(f"é”™è¯¯: {result.stderr}")
            sys.exit(1)
            
        return result
    
    def initialize(self) -> None:
        """åˆå§‹åŒ– Terraform"""
        print(f"åˆå§‹åŒ– Terraform ({self.environment})...")
        self.run_terraform(["init", "-upgrade"])
    
    def validate(self) -> None:
        """éªŒè¯ Terraform é…ç½®"""
        print("éªŒè¯ Terraform é…ç½®...")
        self.run_terraform(["validate"])
    
    def plan(self, output_file: str = "tfplan") -> str:
        """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        print(f"ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ ({self.environment})...")
        result = self.run_terraform([
            "plan",
            "-out", output_file,
            "-var", f"environment={self.environment}"
        ])
        return result.stdout
    
    def apply(self, plan_file: str = "tfplan") -> Dict[str, Any]:
        """åº”ç”¨ Terraform é…ç½®"""
        print(f"åº”ç”¨ Terraform é…ç½® ({self.environment})...")
        result = self.run_terraform(["apply", "-auto-approve", plan_file])
        
        # è·å–è¾“å‡º
        output_result = self.run_terraform(["output", "-json"])
        return json.loads(output_result.stdout)
    
    def destroy(self) -> None:
        """é”€æ¯åŸºç¡€è®¾æ–½"""
        print(f"é”€æ¯åŸºç¡€è®¾æ–½ ({self.environment})...")
        self.run_terraform(["destroy", "-auto-approve"])
    
    def get_outputs(self) -> Dict[str, Any]:
        """è·å– Terraform è¾“å‡º"""
        result = self.run_terraform(["output", "-json"])
        return json.loads(result.stdout)
    
    def wait_for_service(self, url: str, timeout: int = 300) -> bool:
        """ç­‰å¾…æœåŠ¡å¯ç”¨"""
        import requests
        
        print(f"ç­‰å¾…æœåŠ¡ {url} å¯ç”¨...")
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                response = requests.get(url, timeout=5)
                if response.status_code == 200:
                    print(f"âœ… æœåŠ¡ {url} å·²å°±ç»ª")
                    return True
            except requests.RequestException:
                pass
            
            time.sleep(5)
        
        print(f"âŒ æœåŠ¡ {url} æœªåœ¨ {timeout} ç§’å†…å°±ç»ª")
        return False
    
    def post_deploy_config(self, outputs: Dict[str, Any]) -> None:
        """åéƒ¨ç½²é…ç½®"""
        print("è¿è¡Œåéƒ¨ç½²é…ç½®...")
        
        # é…ç½® Kubernetes
        if "kube_config" in outputs:
            kubeconfig_path = Path.home() / ".kube" / f"config-{self.environment}"
            kubeconfig_path.write_text(outputs["kube_config"]["value"])
            print(f"Kubeconfig ä¿å­˜åˆ° {kubeconfig_path}")
        
        # æ›´æ–° DNS
        if "load_balancer_ip" in outputs:
            self.update_dns(outputs["load_balancer_ip"]["value"])
        
        # é…ç½®ç›‘æ§
        if "monitoring_endpoint" in outputs:
            self.setup_monitoring(outputs["monitoring_endpoint"]["value"])
    
    def update_dns(self, ip: str) -> None:
        """æ›´æ–° DNS è®°å½•"""
        print(f"æ›´æ–° DNS è®°å½•: {ip}")
        # å®ç° DNS æ›´æ–°é€»è¾‘
    
    def setup_monitoring(self, endpoint: str) -> None:
        """è®¾ç½®ç›‘æ§"""
        print(f"è®¾ç½®ç›‘æ§ç«¯ç‚¹: {endpoint}")
        # å®ç°ç›‘æ§è®¾ç½®é€»è¾‘


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="åŸºç¡€è®¾æ–½éƒ¨ç½²è‡ªåŠ¨åŒ–")
    parser.add_argument("action", choices=["plan", "apply", "destroy"], help="è¦æ‰§è¡Œçš„æ“ä½œ")
    parser.add_argument("--environment", "-e", default="staging", help="ç¯å¢ƒåç§°")
    parser.add_argument("--terraform-dir", "-t", default="terraform", help="Terraform ç›®å½•")
    
    args = parser.parse_args()
    
    deployer = InfrastructureDeployer(
        environment=args.environment,
        terraform_dir=args.terraform_dir
    )
    
    try:
        deployer.initialize()
        deployer.validate()
        
        if args.action == "plan":
            plan = deployer.plan()
            print(plan)
        
        elif args.action == "apply":
            deployer.plan()
            outputs = deployer.apply()
            
            # ç­‰å¾…æœåŠ¡å¯ç”¨
            if "load_balancer_url" in outputs:
                deployer.wait_for_service(outputs["load_balancer_url"]["value"])
            
            # åéƒ¨ç½²é…ç½®
            deployer.post_deploy_config(outputs)
            
            print("âœ… éƒ¨ç½²å®Œæˆ!")
            print(f"è¾“å‡º: {json.dumps(outputs, indent=2)}")
        
        elif args.action == "destroy":
            confirm = input(f"ç¡®è®¤é”€æ¯ {args.environment} ç¯å¢ƒ? (yes/no): ")
            if confirm.lower() == "yes":
                deployer.destroy()
                print("âœ… åŸºç¡€è®¾æ–½å·²é”€æ¯")
    
    except KeyboardInterrupt:
        print("\næ“ä½œå·²å–æ¶ˆ")
        sys.exit(1)
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
```

## ç›‘æ§å’Œå¯è§‚æµ‹æ€§

è‡ªåŠ¨åŒ–ç›‘æ§å’Œå‘Šè­¦è®¾ç½®ã€‚

### .github/workflows/monitoring.yml

```yaml
name: Monitoring Setup

on:
  push:
    branches: [main]
    paths: ['monitoring/**']
  workflow_dispatch:

jobs:
  deploy-monitoring:
    name: Deploy Monitoring Stack
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½® kubectl
        uses: azure/setup-kubectl@v3
      
      - name: é…ç½® kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $HOME/.kube/config
      
      - name: éƒ¨ç½² Prometheus
        run: |
          kubectl apply -f monitoring/prometheus/
          kubectl wait --for=condition=available --timeout=300s \
            deployment/prometheus-server -n monitoring
      
      - name: éƒ¨ç½² Grafana
        run: |
          kubectl apply -f monitoring/grafana/
          kubectl wait --for=condition=available --timeout=300s \
            deployment/grafana -n monitoring
      
      - name: é…ç½® Grafana æ•°æ®æº
        run: |
          kubectl apply -f monitoring/grafana/datasources/
      
      - name: å¯¼å…¥ Grafana ä»ªè¡¨æ¿
        run: |
          kubectl apply -f monitoring/grafana/dashboards/
      
      - name: éƒ¨ç½² Alertmanager
        run: |
          kubectl apply -f monitoring/alertmanager/
      
      - name: éƒ¨ç½² Node Exporter
        run: |
          kubectl apply -f monitoring/node-exporter/
      
      - name: éªŒè¯ç›‘æ§å †æ ˆ
        run: |
          kubectl get pods -n monitoring
          kubectl get services -n monitoring
```

### monitoring/dashboards/application-dashboard.json

```json
{
  "dashboard": {
    "title": "åº”ç”¨ç¨‹åºç›‘æ§",
    "panels": [
      {
        "title": "è¯·æ±‚ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "é”™è¯¯ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "5xx é”™è¯¯"
          }
        ]
      },
      {
        "title": "å»¶è¿Ÿ",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P95 å»¶è¿Ÿ"
          },
          {
            "expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P99 å»¶è¿Ÿ"
          }
        ]
      },
      {
        "title": "CPU ä½¿ç”¨ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(process_cpu_seconds_total[5m])",
            "legendFormat": "{{instance}}"
          }
        ]
      },
      {
        "title": "å†…å­˜ä½¿ç”¨ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "process_resident_memory_bytes",
            "legendFormat": "{{instance}}"
          }
        ]
      }
    ]
  }
}
```

## æ–‡æ¡£ç”Ÿæˆ

è‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆå’Œæ›´æ–°ã€‚

### .github/workflows/docs.yml

```yaml
name: Documentation

on:
  push:
    branches: [main]
    paths: ['**.md', 'docs/**']
  workflow_dispatch:

jobs:
  generate-docs:
    name: Generate Documentation
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: è®¾ç½® Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: å®‰è£…ä¾èµ–
        run: |
          pip install mkdocs mkdocs-material mkdocs-gen-files
      
      - name: ç”Ÿæˆ API æ–‡æ¡£
        run: |
          mkdocs gen-files
          mkdocs build
      
      - name: éƒ¨ç½²åˆ° GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./site
```

## å®‰å…¨æ‰«æ

è‡ªåŠ¨åŒ–å®‰å…¨æ‰«æå’Œåˆè§„æ£€æŸ¥ã€‚

### .github/workflows/security.yml

```yaml
name: Security Scan

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    - cron: '0 6 * * 1'  # æ¯å‘¨ä¸€æ—©ä¸Š 6 ç‚¹è¿è¡Œ
  workflow_dispatch:

jobs:
  # ä¾èµ–æ‰«æ
  dependency-scan:
    name: Dependency Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è¿è¡Œ Snyk
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
      
      - name: è¿è¡Œ npm audit
        run: npm audit --audit-level=high
        continue-on-error: true

  # é™æ€åˆ†æ
  static-analysis:
    name: Static Analysis
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è¿è¡Œ CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: javascript, python
      
      - name: æ‰§è¡Œ CodeQL åˆ†æ
        uses: github/codeql-action/analyze@v3

  # å®¹å™¨æ‰«æ
  container-scan:
    name: Container Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: æ„å»ºæµ‹è¯•é•œåƒ
        run: docker build -t test-image .
      
      - name: è¿è¡Œ Trivy
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: test-image
          format: 'table'
          exit-code: '1'
          severity: 'CRITICAL,HIGH'

  # å¯†é’¥æ‰«æ
  secret-scan:
    name: Secret Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: è¿è¡Œ Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # è®¸å¯è¯åˆè§„
  license-compliance:
    name: License Compliance
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
      
      - name: è¿è¡Œ FOSSA
        uses: fossas/fossa-action@v1
        with:
          api-key: ${{ secrets.FOSSA_API_KEY }}
```

## ä¾èµ–æ›´æ–°

è‡ªåŠ¨åŒ–ä¾èµ–æ›´æ–°å’Œç®¡ç†ã€‚

### .github/workflows/dependencies.yml

```yaml
name: Dependency Updates

on:
  schedule:
    - cron: '0 6 * * 1'  # æ¯å‘¨ä¸€æ—©ä¸Š 6 ç‚¹è¿è¡Œ
  workflow_dispatch:

jobs:
  update-dependencies:
    name: Update Dependencies
    runs-on: ubuntu-latest
    steps:
      - name: Checkoutä»£ç 
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: è®¾ç½® Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
      
      - name: è¿è¡Œ Renovate
        uses: renovatebot/github-action@v40.0.6
        with:
          configurationFile: .github/renovate.json
          token: ${{ secrets.RENOVATE_TOKEN }}
```

### .github/renovate.json

```json
{
  "extends": [
    "config:base",
    ":dependencyDashboard",
    ":semanticCommits",
    ":automergeDigest",
    ":automergePatch",
    ":automergeBranchPush",
    ":rebaseStalePrs",
    ":prHourlyLimitNone",
    ":prConcurrentLimitNone"
  ],
  "labels": ["dependencies", "renovate"],
  "assignees": ["@maintainer-team"],
  "reviewers": ["@reviewer-team"],
  "timezone": "Asia/Shanghai",
  "schedule": ["every weekday"],
  "commitMessagePrefix": "chore(deps): ",
  "commitMessageAction": "æ›´æ–°",
  "commitMessageTopic": "{{depName}}",
  "vulnerabilityAlerts": {
    "labels": ["security"],
    "assignees": []
  },
  "packageRules": [
    {
      "matchPackagePatterns": ["^@types/"],
      "automerge": true
    },
    {
      "matchPackagePatterns": ["^eslint", "^prettier"],
      "automerge": true
    },
    {
      "matchDepTypes": ["devDependencies"],
      "automerge": true
    },
    {
      "matchUpdateTypes": ["patch", "minor"],
      "automerge": true
    },
    {
      "matchUpdateTypes": ["major"],
      "automerge": false
    }
  ],
  "lockFileMaintenance": {
    "enabled": true,
    "schedule": ["before 3am on Monday"]
  }
}
```

## å·¥ä½œæµç¼–æ’

ä½¿ç”¨ TypeScript ç¼–æ’å¤æ‚å·¥ä½œæµã€‚

### scripts/workflow-orchestrator.ts

```typescript
/**
 * å·¥ä½œæµç¼–æ’å™¨
 * 
 * ç¼–æ’å’Œè‡ªåŠ¨åŒ–å¤æ‚çš„å¤šæ­¥éª¤å·¥ä½œæµ
 */

import { exec } from 'child_process';
import { promisify } from 'util';
import * as fs from 'fs/promises';
import * as path from 'path';

const execAsync = promisify(exec);


interface WorkflowStep {
  name: string;
  command: string;
  args?: string[];
  cwd?: string;
  env?: Record<string, string>;
  continueOnError?: boolean;
  timeout?: number;
}


interface WorkflowConfig {
  name: string;
  description: string;
  steps: WorkflowStep[];
  onFailure?: WorkflowStep[];
  onSuccess?: WorkflowStep[];
}


interface WorkflowResult {
  success: boolean;
  steps: Map<string, boolean>;
  duration: number;
  error?: Error;
}


class WorkflowOrchestrator {
  private workflows: Map<string, WorkflowConfig> = new Map();

  /**
   * æ³¨å†Œå·¥ä½œæµ
   */
  registerWorkflow(config: WorkflowConfig): void {
    this.workflows.set(config.name, config);
  }

  /**
   * ä»æ–‡ä»¶åŠ è½½å·¥ä½œæµ
   */
  async loadWorkflow(filePath: string): Promise<void> {
    const content = await fs.readFile(filePath, 'utf-8');
    const config: WorkflowConfig = JSON.parse(content);
    this.registerWorkflow(config);
  }

  /**
   * åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰å·¥ä½œæµ
   */
  async loadWorkflowsFromDir(dir: string): Promise<void> {
    const files = await fs.readdir(dir);
    const jsonFiles = files.filter(f => f.endsWith('.json'));

    for (const file of jsonFiles) {
      await this.loadWorkflow(path.join(dir, file));
    }
  }

  /**
   * æ‰§è¡Œå·¥ä½œæµ
   */
  async executeWorkflow(name: string, context?: Record<string, string>): Promise<WorkflowResult> {
    const workflow = this.workflows.get(name);
    if (!workflow) {
      throw new Error(`å·¥ä½œæµ ${name} æœªæ‰¾åˆ°`);
    }

    const startTime = Date.now();
    const steps = new Map<string, boolean>();
    let lastError: Error | undefined;

    console.log(`ğŸš€ å¼€å§‹å·¥ä½œæµ: ${workflow.name}`);
    console.log(`ğŸ“ ${workflow.description}`);

    try {
      // æ‰§è¡Œä¸»è¦æ­¥éª¤
      for (const step of workflow.steps) {
        const success = await this.executeStep(step, context);
        steps.set(step.name, success);

        if (!success && !step.continueOnError) {
          throw new Error(`æ­¥éª¤ ${step.name} å¤±è´¥`);
        }
      }

      // æ‰§è¡ŒæˆåŠŸå›è°ƒ
      if (workflow.onSuccess) {
        console.log('âœ… æ‰§è¡ŒæˆåŠŸå›è°ƒ...');
        for (const step of workflow.onSuccess) {
          await this.executeStep(step, context);
        }
      }

      const duration = Date.now() - startTime;
      console.log(`âœ… å·¥ä½œæµ ${name} å®Œæˆ (${duration}ms)`);

      return {
        success: true,
        steps,
        duration
      };

    } catch (error) {
      lastError = error as Error;
      console.error(`âŒ å·¥ä½œæµ ${name} å¤±è´¥:`, error);

      // æ‰§è¡Œå¤±è´¥å›è°ƒ
      if (workflow.onFailure) {
        console.log('ğŸ”§ æ‰§è¡Œå¤±è´¥å›è°ƒ...');
        for (const step of workflow.onFailure) {
          await this.executeStep(step, context);
        }
      }

      const duration = Date.now() - startTime;
      return {
        success: false,
        steps,
        duration,
        error: lastError
      };
    }
  }

  /**
   * æ‰§è¡Œå•ä¸ªæ­¥éª¤
   */
  private async executeStep(step: WorkflowStep, context?: Record<string, string>): Promise<boolean> {
    console.log(`â–¶ï¸  æ‰§è¡Œæ­¥éª¤: ${step.name}`);

    try {
      const startTime = Date.now();
      
      // æ›¿æ¢ä¸Šä¸‹æ–‡å˜é‡
      const command = this.interpolateContext(step.command, context);
      const args = step.args?.map(arg => this.interpolateContext(arg, context)) || [];

      const cwd = step.cwd || process.cwd();
      const env = { ...process.env, ...step.env, ...context };

      const execOptions = {
        cwd,
        env: env as NodeJS.ProcessEnv,
        timeout: step.timeout || 300000
      };

      const fullCommand = args.length > 0 ? `${command} ${args.join(' ')}` : command;
      const { stdout, stderr } = await execAsync(fullCommand, execOptions);

      const duration = Date.now() - startTime;
      console.log(`âœ… æ­¥éª¤ ${step.name} å®Œæˆ (${duration}ms)`);
      
      if (stdout) console.log(`è¾“å‡º: ${stdout}`);
      if (stderr) console.error(`é”™è¯¯: ${stderr}`);

      return true;

    } catch (error) {
      console.error(`âŒ æ­¥éª¤ ${step.name} å¤±è´¥:`, error);
      return false;
    }
  }

  /**
   * æ›¿æ¢ä¸Šä¸‹æ–‡å˜é‡
   */
  private interpolateContext(text: string, context?: Record<string, string>): string {
    if (!context) return text;

    return text.replace(/\{\{(\w+)\}\}/g, (match, key) => {
      return context[key] || match;
    });
  }

  /**
   * åˆ—å‡ºæ‰€æœ‰å·¥ä½œæµ
   */
  listWorkflows(): string[] {
    return Array.from(this.workflows.keys());
  }

  /**
   * è·å–å·¥ä½œæµé…ç½®
   */
  getWorkflow(name: string): WorkflowConfig | undefined {
    return this.workflows.get(name);
  }
}


// ç¤ºä¾‹å·¥ä½œæµé…ç½®
const deploymentWorkflow: WorkflowConfig = {
  name: 'deploy-application',
  description: 'éƒ¨ç½²åº”ç”¨ç¨‹åºåˆ°ç”Ÿäº§ç¯å¢ƒ',
  steps: [
    {
      name: 'è¿è¡Œæµ‹è¯•',
      command: 'npm',
      args: ['test'],
      continueOnError: false
    },
    {
      name: 'æ„å»ºåº”ç”¨',
      command: 'npm',
      args: ['run', 'build'],
      continueOnError: false
    },
    {
      name: 'æ„å»º Docker é•œåƒ',
      command: 'docker',
      args: ['build', '-t', 'app:latest', '.'],
      continueOnError: false
    },
    {
      name: 'æ¨é€é•œåƒ',
      command: 'docker',
      args: ['push', 'app:latest'],
      continueOnError: false,
      env: {
        DOCKER_REGISTRY: process.env.DOCKER_REGISTRY || ''
      }
    },
    {
      name: 'éƒ¨ç½²åˆ° Kubernetes',
      command: 'kubectl',
      args: ['apply', '-f', 'k8s/'],
      continueOnError: false
    },
    {
      name: 'éªŒè¯éƒ¨ç½²',
      command: 'kubectl',
      args: ['rollout', 'status', 'deployment/app'],
      continueOnError: false,
      timeout: 600000
    }
  ],
  onSuccess: [
    {
      name: 'è¿è¡Œå¥åº·æ£€æŸ¥',
      command: 'npm',
      args: ['run', 'health-check']
    },
    {
      name: 'å‘é€æˆåŠŸé€šçŸ¥',
      command: 'node',
      args: ['scripts/notify.js', 'success']
    }
  ],
  onFailure: [
    {
      name: 'å›æ»šéƒ¨ç½²',
      command: 'kubectl',
      args: ['rollback', 'deployment/app']
    },
    {
      name: 'å‘é€å¤±è´¥é€šçŸ¥',
      command: 'node',
      args: ['scripts/notify.js', 'failure']
    }
  ]
};


// ä½¿ç”¨ç¤ºä¾‹
async function main() {
  const orchestrator = new WorkflowOrchestrator();

  // æ³¨å†Œå·¥ä½œæµ
  orchestrator.registerWorkflow(deploymentWorkflow);

  // ä»æ–‡ä»¶åŠ è½½å·¥ä½œæµ
  await orchestrator.loadWorkflowsFromDir('./workflows');

  // æ‰§è¡Œå·¥ä½œæµ
  const context = {
    BRANCH: 'main',
    VERSION: '1.0.0',
    ENVIRONMENT: 'production'
  };

  const result = await orchestrator.executeWorkflow('deploy-application', context);

  if (result.success) {
    console.log('âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ');
    console.log(`æ­¥éª¤: ${Array.from(result.steps.entries()).map(([k, v]) => `${k}: ${v}`).join(', ')}`);
    console.log(`æ€»è€—æ—¶: ${result.duration}ms`);
  } else {
    console.error('âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥');
    console.error(`é”™è¯¯: ${result.error?.message}`);
    process.exit(1);
  }
}


if (require.main === module) {
  main().catch(console.error);
}

export { WorkflowOrchestrator, WorkflowConfig, WorkflowStep, WorkflowResult };
```

## æœ€ä½³å®è·µ

1. **å·¥ä½œæµè®¾è®¡**
   - ä¿æŒå·¥ä½œæµç®€å•å’Œæ¨¡å—åŒ–
   - ä½¿ç”¨å¯é‡ç”¨çš„ action å’Œæ¨¡æ¿
   - ä¼˜åŒ–ç¼“å­˜ç­–ç•¥ä»¥å‡å°‘æ„å»ºæ—¶é—´
   - å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘

2. **å®‰å…¨æ€§**
   - ä½¿ç”¨ GitHub Secrets å­˜å‚¨æ•æ„Ÿä¿¡æ¯
   - å®æ–½æœ€å°æƒé™åŸåˆ™
   - å®šæœŸæ‰«æä¾èµ–é¡¹å’Œå®¹å™¨é•œåƒ
   - ä½¿ç”¨ç­¾åçš„æäº¤å’Œæ ‡ç­¾

3. **ç›‘æ§å’Œå‘Šè­¦**
   - ä¸ºå…³é”®å·¥ä½œæµé…ç½®é€šçŸ¥
   - è·Ÿè¸ªå·¥ä½œæµæ‰§è¡Œæ—¶é—´
   - è®¾ç½® SLA å’Œ SLO
   - å®ç°è‡ªåŠ¨å›æ»šæœºåˆ¶

4. **ç»´æŠ¤**
   - å®šæœŸæ›´æ–°ä¾èµ–é¡¹
   - å®šæœŸå®¡æŸ¥å’Œä¼˜åŒ–å·¥ä½œæµ
   - ä¿æŒæ–‡æ¡£æ›´æ–°
   - ä½¿ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬æ§åˆ¶

## ç›¸å…³æŠ€èƒ½

- [cloud-architect](../agents/cloud-architect.md) - äº‘æ¶æ„è®¾è®¡
- [devops-troubleshooter](../agents/devops-troubleshooter.md) - DevOps æ•…éšœæ’æŸ¥
- [kubernetes-architect](../agents/kubernetes-architect.md) - Kubernetes æ¶æ„
- [terraform-specialist](../agents/terraform-specialist.md) - Terraform ä¸“æ‰
